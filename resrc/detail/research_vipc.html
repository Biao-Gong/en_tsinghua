<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">


    <title>View-Guided Point Cloud Completion</title>

    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
    <link href="../../static/carousel.css" rel="stylesheet">
    <link rel="stylesheet" href="../../static/css/vendor/glyphicons/glyphicons.css">
    <link rel="stylesheet" href="../../static/css/vendor/glyphicons/filetypes.css">
    <link rel="stylesheet" href="../../static/css/vendor/glyphicons/social.css">
    <link href="../../../fonts.googleapis.com/css-family=Open+Sans-400,700,600.css" rel='stylesheet' type='text/css'>
    <link href="../../static/trans.css" rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="../../../maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../static/css/bootstrap-markdown.min.css" type="text/css">
    <link rel="stylesheet" href="../../static/css/vendor/layerslider/layerslider.css" type="text/css">
    <link rel="stylesheet" href="../../static/css/styles-cleanred.css" id="grove-styles">
    <link rel="stylesheet" href="../../../cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" type="text/css">
    <link rel="stylesheet" href="../../static/css/nlp.css" id="nlp-styles">
    <script src="../../../ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../static/js/vendor/jquery/jquery-1.9.1.min.js"><\/script>')</script>
    <script src="../../static/js/vendor/layerslider/greensock.js" type="text/javascript"></script>
    <script src="../../static/js/vendor/layerslider/layerslider.transitions.js" type="text/javascript"></script>
    <script src="../../static/js/vendor/layerslider/layerslider.kreaturamedia.jquery.js"
        type="text/javascript"></script>
    <script src="../../static/js/markdown.js" type="text/javascript"></script>
    <script src="../../static/js/to-markdown.js" type="text/javascript"></script>
    <script src="../../static/js/bootstrap-markdown.js" type="text/javascript"></script>
    <script src="../../static/js/grove-slider.js" type="text/javascript"></script>
    <script src="../../../cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script>
    <script
        src="../../../cdn.datatables.net/plug-ins/1.10.7/features/searchHighlight/dataTables.searchHighlight.min.js"></script>
    <script src="../../../bartaz.github.io/sandbox.js/jquery.highlight.js"></script>
    <link href="../../../cdnjs.cloudflare.com/ajax/libs/select2/4.0.3/css/select2.min.css" rel="stylesheet" />
    <script src="../../../cdnjs.cloudflare.com/ajax/libs/select2/4.0.3/js/select2.min.js"></script>
    <link href="static/css/c5e0117592e540848259ae6882d93f52.css" rel="stylesheet" />
    <script src="static/js/d46d827d0f604446b58cc8d38bdbd84e.js"></script>

</head>

<body>
    <header>
        <nav class="navbar navbar-default grove-navbar navbar-fixed-top" id="imoonbignav">
            <div class="container" id="imoonmidnav">
                <div class="navbar-header">
                    <a href="#" class="grove-toggle collapsed" data-toggle="collapse" data-target=".grove-nav">
                        <i class="glyphicons show_lines"></i>
                    </a>
                    <img class="navbar-brand navbar-left hidden-xs" src="../../static/img/logos/nlp-logo-small.png"
                        alt="" id="imoonlogo">
                    <a class="navbar-brand navbar-left" href="../index.htm">
                        <h3 class="hidden-xs" id="imoontitle" style="font-weight: 600;margin-top: 15px">iMoon-Lab<p
                                style="margin-top: 5px">
                                iMoon: Intelligent
                                Media and Cognition Lab</p>
                        </h3>
                        <h3 class="hidden-sm hidden-md hidden-lg hidden-xl" style="color: white">iMoon-Lab</h3>
                    </a>
                </div>

                <div class="navbar-collapse grove-nav collapse" style="position: relative">
                    <ul class="nav navbar-nav" id="imoonnav">

                        <div style="position:absolute;top:5px;left:10px;border:0px solid rgb(255, 255, 255);">
                            <a href="../../index.htm">
                                <div style="width: 400px;height:65px"></div>
                            </a>
                        </div>
                        <!-- <div id="language">
                            <a id='drump' href="#"><b>ä¸­ / </b></a><a id='drump'
                                href="../../../en/resrc/index.htm"><b>En</b></a>
                        </div> -->
                        <li style="margin-top: 1px;">
                            <a href="../../index.htm">Home</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../people/index.htm">People</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../resrc/index.htm">Research</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../pubs/index.htm">Publications</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="../../blog/index.htm">News</a>
                        </li>
                        <li style="margin-top: 1px;">
                            <a href="#">Life</a>
                        </li>
                        <li class="dropdown" style="margin-top: 1px;">
                            <a href="#">More</a>
                            <ul class="dropdown-menu">
                                <li><a href="../../more/index.htm">MICCAI19 Tutorial</a></li>
                                <li><a href="#">MICCAI19 Challenge</a></li>
                            </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>

    <div class="container body-content" style="margin-top:90px;">

        <body>
            <h1 align="center" style="font-size:40px;"><b>View-Guided Point Cloud Completion
            </h1>
            <div class="row">
                <br>
                <p align="center" style="font-size:20px;">
                    Xuancheng Zhang
                    <!-- ,
                    Changqing Zou,
                    Yipeng Li,
                    Xibin Zhao,
                    and
                    <a href="http://gaoyue.org/cn/people/gaoyue_index.html">Yue Gao</a> -->
                </p>
            </div>

            <br>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10" style="word-wrap:break-word;hyphens:manual">
                    <!-- <h2><b>Abstract</b></h2> -->
                    <p style="font-size:20px;" wrap="soft">This paper presents a view-guided solution for the task of point cloud completion. Unlike most existing methods directly inferring the missing points using shape priors, we address this task by introducing ViPC (view-guided point cloud completion) that takes the missing crucial global structure information from an extra single-view image. By leveraging a framework 
                        that sequentially performs effective cross-modality and cross-level fusions, our method achieves significantly superior results over typical existing solutions on a new large-scale dataset we collect for the view-guided point cloud completion task. 
                    </p>
                    <p style="text-align:center;"><img style="width: 100%;" src="research_vipc/pipeline.png" alt="xxxx"
                            class="center"></p>
                    <p style="font-size:15px; text-align:center">Figure 1. Architecture of the proposed ViPC. The first stage is used to address the cross-modality fusion problem. It maps image to a coarse representation of point cloud. THe second stage generates a coarse point cloud and the last stage enhances it and produce a higher-quality completed point cloud.</p>
                </div>
                <div class="col-md-1"></div>
            </div>

            <br>


            <br>

            <!-- <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">
                    <h2><b> Method </b></h2>
                </div>
                <div class="col-md-1"></div>
            </div>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">

                    <p style="font-size:20px" wrap="hard">
                        The proposed AMFNet, as illustrated in Figure 1, mainly contains three sequential modules: a 2D
                        segmentation network,
                        a 2D-3D projection layer, and a two-branch 3D volume network. This network takes single-view
                        RGB-D images
                        as input and outputs occupancy and semantic labels for all voxels in the scene. The whole
                        network can be trained
                        in an end-to-end manner. We next introduce each module in the sequence of the flow of data
                        processing. <br><br>

                        The 2D segmentation network extracts 2D geometry features and performs 2D semantic segment-ation
                        from the input RGB-D images.
                        <br>
                        The 2D-3D projection layer projects every feature tensor and semantic label into the 3D volume
                        at the location with the same depth value.<br>
                        The 3D volume network, which takes the output of the 2D-3D projection layer as input, contains
                        two branches: one
                        for 3D guidance information and the other for 3D semantic completion.
                    </p>


                    <p style="text-align:center;"><img style="width: 60%;" src="research_AMFNet/RAB.png" alt="xxxx"
                            class="center"></p>
                    <p style="font-size:15px; text-align:center;">Figure 2. Illustration of the proposed residual
                        attention block
                        (RAB). RAB has a structure similar to the DDR block but with both channel-wise and spatial-wise
                        attention injected.
                    </p>
                    <br>

                    <p style="font-size:20px" wrap="hard">
                        The 3D-guidance branch is used to provide the guidance information for the branch of 3D semantic
                        completion, which is boosted from an initial 3D semantic volumetric scene where visible voxels
                        have initial
                        semantic labels. The initial 3D semantic volume is encoded by a one-hot encoder to achieve an
                        ROI region (3D
                        bounding box) for a specific category from the initial 3D semantic volume. The one-hot encoding
                        introduces spatial
                        boundary constraints into the network for each category, which improves the prediction of 3D
                        semantic volume. <br><br>

                        The 3D-semantic completion branch, which takes the initial 3D feature volume as input, is mainly
                        used to infer the voxel occupancy
                        of the 3D scene. The RAB block used in the 3D-completion branch is shown in Figure 2.

                    </p>

                </div>
                <div class="col-md-1"></div>
            </div> -->

            <br>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10" style="word-wrap:break-word;hyphens:manual">
                    <h2><b>Results</b></h2>

                    <p style="text-align:center;"><img style="width: 100%;" src="research_vipc/table.png" alt="xxxx"
                            class="center"></p>
                    <br>
                    <p style="font-size:20px;" wrap="soft">
                        We normalize the output point clouds produced by the comparison methods and caluculate the CD and F-Score on the 2048 points of each shape. The results on each categories and the average are summmarized in Table 1 and 2. The proposed method consisitenly outperforms other methods with a significant margin on all the eight categories on both CD and F-Score metrics.

                    </p>

                    <br>

                    <p style="text-align:center;"><img style="width: 100%;" src="research_vipc/qualitative.png" alt="xxxx"
                            class="center"></p>
                    <p style="font-size:15px; text-align:center">
                        Figure 2. Qualitative comparison on ShapeNet-ViPC. Our method outperforms other baseline methods with significant margins. The resolution for partial, completed and groud truth point clouds are 2,048.</p>
                    <p style="font-size:20px;" wrap="soft">
                        Figure 2 shows the qualitative results produced by the comparison methods for a more comprehensive evaluation. It is easy to observe that the completed point clouds produced by FoldingNet are relatively messy. The generated point clouds do not show clear structures on some shape parts, e.g., the wings of the airplane, the chair legs, the table legs. PCN and AtlasNet produce improved qualitative results compared to FoldingNet overall.
                        The structured-tree based TopNet method achieves better visual results than PCN and AtlasNet in general. We can see the evidences on the airplane, lamp, sofa, and watercraft, which exhibits much clearer part structures and points arranged more neatly. However, some part details in the input partial point clouds are not preserved in the completed point clouds, e.g., the points of the fuel tank of the airplane and 
                        the trestle of the table have been moved to other parts. Results produced by our method have no this problem and show visually better performance on all eight categories than baselines.
                    </p>

                    <br>

                    <p style="text-align:center;"><img style="width: 75%;" src="research_vipc/view-contribution.png" alt="xxxx"
                            class="center"></p>
                    <p style="font-size:15px; text-align:center">
                        Figure 3. Views provides more complementary information for the input partial point clouds can produce better completion results. Each input partial point clouds are shown on the left; quantitative completion performance measured by the average CD is reported below each input reference view.</p>
                    <p style="font-size:20px;" wrap="soft">
                        We study wyhat kind of input view can better improve the completion. We randomly select 400 partial point cloud from the test set of ShapeNet-ViPC for the evalution. We quantify the completion quality of those 400 completion point clouds with the CD metric and demonstrate some representative results in Figure 3.
                        It indicates that different image views can provide different improvement. The image views which can provide more information for the missing part of the partial point would produce better results.
                        

                    </p>

                </div>
                <div class="col-md-1"></div>
            </div>

            <br>

            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10" style="word-wrap:break-word;hyphens:manual">
                    <h2><b>Data and code</b></h2>
                    <p style="font-size:20px;" wrap="soft">
                        Coming soon.
                    </p>

                </div>
                <div class="col-md-1"></div>
            </div>

            <br>

            <!--
            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">
                    <h2><b> Citation </b></h2>

                </div>
                <div class="col-md-1"></div>
            </div>
            <div class="row">
                <div class="col-md-1"></div>
                <div class="col-md-10">

                    <br>
                    <br>
                    <p style="font-size=40px">
                        <a class="btn btn-default" href="#"> <b> Paper &raquo;</b></a>
                        <a class="btn btn-default" href="#"> <b> Code &raquo;</b></a>
                    </p>
                </div>


                <div class="col-md-1"></div>
            </div> -->




        </body>



        <hr />
        <footer style="background-color: #ffffff;">
                <p>&copy; 2020 - iMoon: Intelligent Media and Cognition Lab - Tsinghua</p>
        </footer>
    </div>
    <script src="static/js/77c25eff67b24c0aa003ead7859d1511.js"></script>

    <script src="static/js/1a59a27fb4484e89ab0510a5871211bd.js"></script>

    <script src="static/js/jquery-ui.min.js"></script>

    <link href="static/css/jquery-ui.min.css" rel="stylesheet" />

    <script src="static/js/shortcut.js"></script>

    <script src="static/js/suggest.js"></script>




</body>

</html>
